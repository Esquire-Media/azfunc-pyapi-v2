{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "for k,v in json.load(open(\"local.settings.json\"))[\"Values\"].items():\n",
    "    os.environ[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.data import register_binding, from_bind\n",
    "import os \n",
    "if not from_bind(\"fsq\"):\n",
    "    register_binding(\n",
    "        \"fsq\",\n",
    "        \"Structured\",\n",
    "        \"sql\",\n",
    "        url=os.environ[\"DATABIND_SQL_FOURSQUARE\"],\n",
    "        schemas=[\"dbo\"],\n",
    "    )\n",
    "if not from_bind(\"legato\"):\n",
    "    register_binding(\n",
    "        \"legato\",\n",
    "        \"Structured\",\n",
    "        \"sql\",\n",
    "        url=os.environ[\"DATABIND_SQL_KEYSTONE\"],\n",
    "        schemas=[\"poi\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Create connection objects (adjust if needed)\n",
    "fsq_conn = from_bind(\"fsq\").connect().connection()\n",
    "legato_conn = from_bind(\"legato\").connect().connection()\n",
    "\n",
    "# Define your SQL query (ensure it returns all desired columns, including the unique id)\n",
    "sql_query = \"SELECT DISTINCT * FROM dbo.poi\"\n",
    "\n",
    "# Set the batch size\n",
    "chunksize = 100000\n",
    "first_chunk = True\n",
    "total_records_inserted = 0\n",
    "\n",
    "# Global containers for deduplication and many-to-many mappings\n",
    "# For categories: key = category_id, value = category_label\n",
    "categories_global = {}\n",
    "# Set of tuples: (poi_id, category_id)\n",
    "poi_categories_set = set()\n",
    "\n",
    "# For chains: key = chain_id, value = chain_name\n",
    "chains_global = {}\n",
    "# Set of tuples: (poi_id, chain_id)\n",
    "poi_chains_set = set()\n",
    "\n",
    "# Stream the data in chunks\n",
    "for chunk in pd.read_sql(sql=sql_query, con=fsq_conn, chunksize=chunksize):\n",
    "    chunk.rename(columns={\"fsq_id\": \"id\"}, inplace=True)\n",
    "    # Convert the date columns explicitly to Python date objects\n",
    "    for col in ['date_created', 'date_refreshed', 'date_closed']:\n",
    "        if col in chunk.columns:\n",
    "            chunk[col] = pd.to_datetime(chunk[col]).dt.date\n",
    "\n",
    "    # Process each row for categories and chains\n",
    "    def process_row(row):\n",
    "        poi_id = row['id']  # assuming the primary key is \"id\"\n",
    "        \n",
    "        # Process categories if both columns are available and not null\n",
    "        cat_ids_val = row.get('fsq_category_ids')\n",
    "        cat_labels_val = row.get('fsq_category_labels')\n",
    "        if pd.notnull(cat_ids_val) and pd.notnull(cat_labels_val):\n",
    "            try:\n",
    "                cat_ids = json.loads(cat_ids_val)\n",
    "                cat_labels = json.loads(cat_labels_val)\n",
    "            except Exception as e:\n",
    "                cat_ids, cat_labels = [], []\n",
    "            # Pair each id with its corresponding label\n",
    "            for cat_id, cat_label in zip(cat_ids, cat_labels):\n",
    "                # Update the global categories dict (deduplication)\n",
    "                if cat_id not in categories_global:\n",
    "                    categories_global[cat_id] = cat_label\n",
    "                # Add the mapping (POI to category) to the set\n",
    "                poi_categories_set.add((poi_id, cat_id))\n",
    "        \n",
    "        # Process chains similarly\n",
    "        chain_ids_val = row.get('fsq_chain_id')\n",
    "        chain_names_val = row.get('fsq_chain_name')\n",
    "        if pd.notnull(chain_ids_val) and pd.notnull(chain_names_val):\n",
    "            try:\n",
    "                chain_ids = json.loads(chain_ids_val)\n",
    "                chain_names = json.loads(chain_names_val)\n",
    "            except Exception as e:\n",
    "                chain_ids, chain_names = [], []\n",
    "            for chain_id, chain_name in zip(chain_ids, chain_names):\n",
    "                if chain_id not in chains_global:\n",
    "                    chains_global[chain_id] = chain_name\n",
    "                poi_chains_set.add((poi_id, chain_id))\n",
    "    \n",
    "    # Apply the row-level processing for categories and chains\n",
    "    chunk.apply(process_row, axis=1)\n",
    "    \n",
    "    # Write the main POI data to SQL.\n",
    "    # The first chunk will replace the table; subsequent chunks will append.\n",
    "    chunk.to_sql(\n",
    "        name=\"foursquare\",\n",
    "        con=legato_conn,\n",
    "        schema=\"poi\",\n",
    "        if_exists=\"replace\" if first_chunk else \"append\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    # Print progress information\n",
    "    records_in_chunk = len(chunk)\n",
    "    total_records_inserted += records_in_chunk\n",
    "    print(f\"Inserted {records_in_chunk} records in this iteration. Total inserted so far: {total_records_inserted}.\")\n",
    "    \n",
    "    first_chunk = False\n",
    "\n",
    "# After processing all chunks, create DataFrames for the related tables\n",
    "\n",
    "# Categories table: unique category_id and category_label pairs\n",
    "categories_df = pd.DataFrame([\n",
    "    {\"category_id\": cat_id, \"category_label\": cat_label}\n",
    "    for cat_id, cat_label in categories_global.items()\n",
    "])\n",
    "\n",
    "# Many-to-many mapping for POI to categories\n",
    "poi_categories_df = pd.DataFrame(list(poi_categories_set), columns=[\"poi_id\", \"category_id\"])\n",
    "\n",
    "# Chains table: unique chain_id and chain_name pairs\n",
    "chains_df = pd.DataFrame([\n",
    "    {\"chain_id\": chain_id, \"chain_name\": chain_name}\n",
    "    for chain_id, chain_name in chains_global.items()\n",
    "])\n",
    "\n",
    "# Many-to-many mapping for POI to chains\n",
    "poi_chains_df = pd.DataFrame(list(poi_chains_set), columns=[\"poi_id\", \"chain_id\"])\n",
    "\n",
    "# Write the related tables to SQL. Use \"replace\" to create new tables.\n",
    "categories_df.to_sql(\n",
    "    name=\"foursquare_categories\",\n",
    "    con=legato_conn,\n",
    "    schema=\"poi\",\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "poi_categories_df.to_sql(\n",
    "    name=\"foursquare_poi_categories\",\n",
    "    con=legato_conn,\n",
    "    schema=\"poi\",\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "chains_df.to_sql(\n",
    "    name=\"foursquare_chains\",\n",
    "    con=legato_conn,\n",
    "    schema=\"poi\",\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "poi_chains_df.to_sql(\n",
    "    name=\"foursquare_poi_chains\",\n",
    "    con=legato_conn,\n",
    "    schema=\"poi\",\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "legato_conn.commit()\n",
    "print(\"Completed processing related tables for categories and chains.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

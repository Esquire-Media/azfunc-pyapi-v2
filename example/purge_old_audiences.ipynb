{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orjson, os\n",
    "with open(\"local.settings.json\") as f:\n",
    "    os.environ.update(orjson.loads(f.read())[\"Values\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e055dc",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed22186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(os.environ['DATABIND_SQL_KEYSTONE'])\n",
    "schema = 'keystone'\n",
    "table_name = 'Audience'\n",
    "columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e779331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData, Table, select\n",
    "import pandas as pd\n",
    "\n",
    "# Create a MetaData object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect the table\n",
    "table = Table(table_name, metadata, schema=schema, autoload_with=engine)\n",
    "\n",
    "# select\n",
    "columns = [\"id\", \"status\"]\n",
    "selected_columns = [table.c[col] for col in columns]\n",
    "stmt = select(*selected_columns)\n",
    "\n",
    "# Execute the query\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(stmt)\n",
    "    # Use mappings() to fetch rows as dictionaries\n",
    "    rows = [row for row in result.mappings()]\n",
    "\n",
    "audiences = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b20d4",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7428d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.data.tables import TableClient\n",
    "import pandas as pd\n",
    "\n",
    "def get_partition_keys_from_connection_string(\n",
    "    conn_str: str,\n",
    "    name_filter: str = \"orchestrator_esquire_audience\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame of entities with PartitionKey and Name\n",
    "    where Name == name_filter. Filtering is applied server-side,\n",
    "    and results are ordered by CreatedTime ascending (oldest first).\n",
    "\n",
    "    :param conn_str: Azure Storage connection string\n",
    "    :param name_filter: The value to match in the 'Name' field\n",
    "    :return: pandas DataFrame with PartitionKey, Name, RuntimeStatus, CustomStatus, CreatedTime\n",
    "    \"\"\"\n",
    "    # Initialize client\n",
    "    table_client = TableClient.from_connection_string(conn_str, table_name=\"productionInstances\")\n",
    "\n",
    "    # Select minimal columns to reduce payload\n",
    "    select_fields = [\"PartitionKey\", \"RuntimeStatus\", \"CustomStatus\", \"CreatedTime\"]\n",
    "\n",
    "    # OData filter: property names are case-sensitive to your schema\n",
    "    odata_filter = f\"Name eq '{name_filter}'\"\n",
    "\n",
    "    # Query entities (pagination handled internally)\n",
    "    entities = list(table_client.query_entities(select=select_fields, query_filter=odata_filter))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(entities)\n",
    "\n",
    "    # Parse JSON in CustomStatus safely\n",
    "    if \"CustomStatus\" in df.columns:\n",
    "        df[\"CustomStatus\"] = df[\"CustomStatus\"].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Sort by CreatedTime (ascending, oldest first)\n",
    "    if \"CreatedTime\" in df.columns:\n",
    "        df = df.sort_values(by=\"CreatedTime\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf596d4",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = get_partition_keys_from_connection_string(os.getenv(\"AzureWebJobsStorage\", \"\"))\n",
    "instance_ids = set(instances[\"PartitionKey\"].to_list())\n",
    "audience_ids = set(audiences[audiences[\"status\"]][\"id\"].to_list())\n",
    "absent_audiences = instance_ids - audience_ids\n",
    "display(len(instance_ids & audience_ids))\n",
    "display(len(absent_audiences))\n",
    "display(f\"{len(absent_audiences) / len(instance_ids):.2%} set to be removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8f841",
   "metadata": {},
   "source": [
    "# Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "for id in absent_audiences:\n",
    "    print(id)\n",
    "    resp = requests.delete(\n",
    "        url=\"https://esquire-auto-audience.azurewebsites.net/runtime/webhooks/durabletask/instances/{id}\".format(\n",
    "            id=id\n",
    "        ),\n",
    "        params={\n",
    "            \"taskHub\": \"production\",\n",
    "            \"connection\": \"Storage\",\n",
    "            \"code\": os.environ['AZFUNC_MASTER_CODE'],\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_error_state(v) -> bool:\n",
    "    # v can be a dict, JSON string, or NaN\n",
    "    if isinstance(v, dict):\n",
    "        return v.get(\"state\") == \"Error\"\n",
    "    if pd.isna(v):\n",
    "        return False\n",
    "    try:\n",
    "        obj = json.loads(v)\n",
    "        return isinstance(obj, dict) and obj.get(\"state\") == \"Error\"\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "mask_error = instances[\"CustomStatus\"].apply(has_error_state)\n",
    "\n",
    "instances = get_partition_keys_from_connection_string(\n",
    "    os.getenv(\"AzureWebJobsStorage\", \"\")\n",
    ")\n",
    "failed_ids = instances[\n",
    "    (instances[\"RuntimeStatus\"] == \"Failed\")\n",
    "    # & (\n",
    "    #     ~instances[\"PartitionKey\"].isin(\n",
    "    #         [\n",
    "    #             \"cmea1702f0010twbajoqog052\",\n",
    "    #             \"cmea0y34i000wtwba46i6zsgu\",\n",
    "    #             \"cmg9hmvpx000shfz8s14f2rha\",\n",
    "    #             \"cmggn76i4000avub2r1hl5c0r\",\n",
    "    #             \"cmg6voslk001rhia2p20bjswr\",\n",
    "    #             \"cly1z4etl00232144s3gwe6wm\",\n",
    "    #             \"clz1iu5i2000011il1gcvofz6\",\n",
    "    #             \"clzbmml1g002xern43pnf0b9k\",\n",
    "    #             \"clzojel6m001pzgkp1hcrbn5p\",\n",
    "    #             \"cm3ouvcd0001aze18wmapnmx8\",\n",
    "    #             \"cm4vtqklg00581103ugyr6v7z\",\n",
    "    #             \"cm5mwchc0001kbb7961qxkvyo\",\n",
    "    #             \"cm4vo1apu004n1103v4j4bhmp\",\n",
    "    #             \"cm3j6t1xo000jx2ycxdqgtmwn\",\n",
    "    #             \"cm3sxuzxl000zovfjv79satyl\",\n",
    "    #             \"cm7utgax2003ht62990n4cgkj\",\n",
    "    #             \"cmfzi7usj001e7rt0mnebygfb\",\n",
    "    #             \"cmfzhq2n3001t13vjw235hxql\",\n",
    "    #             \"cmg5igyfy00002ihbwtgf3q5t\",\n",
    "    #             \"cmg5eapst001o146yas6l9ytp\",\n",
    "    #             \"cmfwylljd001213vjqaoyhlq6\",\n",
    "    #             \"cmfvjzn4s000j13vjq9vjegmh\",\n",
    "    #             \"cmfebpmkq0000rmszmzely63n\",\n",
    "    #             \"cmfwyut25000u7rt00g22amjj\",\n",
    "    #             \"cmfzijir4001i7rt0g5duzv0t\",\n",
    "    #             \"cmg5id4le0000vv796gmd1suf\",\n",
    "    #             \"cmfo9uykn000axprcmk6e52e3\",\n",
    "    #             \"cmfv6l5ge00087rt0babmbxji\",\n",
    "    #         ]\n",
    "    #     )\n",
    "    # )\n",
    "    # & ~mask_error\n",
    "][\"PartitionKey\"].to_list()[0:25]\n",
    "\n",
    "for id in failed_ids:\n",
    "    print(id)\n",
    "    requests.delete(\n",
    "        url=\"https://esquire-auto-audience.azurewebsites.net/runtime/webhooks/durabletask/instances/{id}\".format(\n",
    "            id=id\n",
    "        ),\n",
    "        params={\n",
    "            \"taskHub\": \"production\",\n",
    "            \"connection\": \"Storage\",\n",
    "            \"code\": os.environ[\"AZFUNC_MASTER_CODE\"],\n",
    "        },\n",
    "    )\n",
    "    requests.post(\n",
    "        url=\"https://esquire-auto-audience.azurewebsites.net/api/audiences/{id}\".format(\n",
    "            id=id\n",
    "        ),\n",
    "        params={\n",
    "            \"force\": 1,\n",
    "            \"code\": os.environ[\"AZFUNC_MASTER_CODE\"],\n",
    "        },\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
